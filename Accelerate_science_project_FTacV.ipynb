{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Created by Freyja Björk Dagbjartsdóttir 6/3/21 for the Accelerate Science Bootcamp by Cambridge Spark*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes exploratory data analysis and simple linear regression for physical parameter extraction from Fourier Transfrom AC Voltammetry signals. In FTacV one applies large amplitude voltage on an electrochemical system and measures the response current. The large amplitude voltage induces non-linear response from the electrochemical system. The inputs and outputs look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Data/voltage_vs_time.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/current_vs_time.png\" width=\"250\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this system there is 1 electrochemical reaction and no other reaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simulated response is dependent on several physical properties and operational parameters. I have run 10000 simulations where I vary 10 different physical properties randomly (you will see the distributions later). These physical properties can be seperated into mass transfer properties and charge transfer properties: \n",
    "\n",
    "Mass transfer:\n",
    "* Diffusion coefficients of chemical species 1 and 2 ($D1 and $D2)\n",
    "* Electrolyte viscosity ($visc)\n",
    "\n",
    "Charge transfer properties: \n",
    "\n",
    "* Formal potential ($Ezero) \n",
    "\n",
    "* Rate coefficient ($Ks)\n",
    "\n",
    "* Charge transfer coefficeint ($alpha)\n",
    "\n",
    "* System internal resistance ($Ru)\n",
    "\n",
    "* Electrode/electrolyte internal capacitance ($a0,$a1,$a2)\n",
    "\n",
    "In theory we might be able to extract all of these physical parameters from a single measurement, making FTacV a very powerful technique. In reality fitting the curves to the data is a slow process and the understanding of the information hidden in the data is scarce as it can be very hard for the human mind to comprehend all that information at once. Pattern recognising ML algorithms are thus a promising way to get a deeper understanding of the technique.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the amount of data is significant and the processing of it takes a very long time, the process will only be described here and not performed. The data folder contains figures and the final set of data that will be visualised and used for simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the current signal is usually interpreted is that it is fast Fourier transformed into the frequency domain to obtain the separate harmonics of the signal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Data/freq_domain.png\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick out the individual harmonics and inverse transfrom them separately into the time domain to obtain an interpretable response. This response typically looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Data/harmonic0.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic1.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic2.png\" width=\"250\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"Data/harmonic3.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic4.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic5.png\" width=\"250\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce these data sets without loosing much information to look like the one below. This way the dataset is reduced to 1/16th of the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Data/harmonic0_red.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic1_red.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic2_red.png\" width=\"250\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"Data/harmonic3_red.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic4_red.png\" width=\"250\"/> </td>\n",
    "<td> <img src=\"Data/harmonic5_red.png\" width=\"250\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the physical system is embedded in the peak size, shape and location. So instead of throwing the whole time series at a model it might be more beneficial to describe the curves using location and amplitude. This, in principle, is what I do and use in this notebook. Getting this information is a slow process so I will provide the results in  'peaks_for_regression.csv'. There are many ways to present the full data set shown in the first figures to a ML alorithm, but I started with what I think is intuitive for users of this technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bokeh.plotting import Figure, output_notebook, show, save\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.layouts import row, gridplot\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe 'variables' holds our target variables, and peak_info holds descriptions of different peaks amplitudes and location, as well as the value of the minimum current for each harmonic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.read_csv('Data/variables.csv',index_col=0)\n",
    "peak_info = pd.read_csv('Data/peaks_for_regression.csv',header=[0,1,2],index_col=0)\n",
    "harmonics_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the following cell to get better sense of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic = slice(None)\n",
    "data_type = 'min_value'\n",
    "peak_number = slice(None)\n",
    "peak_info.loc[:,(harmonic,data_type,peak_number)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and sorting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sorts the data depending on if the reaction can be classified as reversible or not. It is common practice to distinguish between reversible or irreversible reactions in electrochemistry.\n",
    "\n",
    "To aid with visualisations later on, reversible reactions will be labelled *blue* and irreversible reactions will be labelled *red*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by reversibility:\n",
    "variables_rev = variables.copy()\n",
    "variables_rev.insert(0,'Is reversible',None)\n",
    "reversible_mask = variables_rev['$Ks'] >= 0.1\n",
    "\n",
    "for i in range(len(reversible_mask)):\n",
    "    if reversible_mask.iloc[i] == True:\n",
    "        variables_rev['Is reversible'].iloc[i] = 'blue'\n",
    "    else:\n",
    "        variables_rev['Is reversible'].iloc[i] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_rev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the different variables are randomly generated individually, some of the simulations will not be representative of measurements one would do. One would always adjust experimental parameters so that the maximum peaks are clear and visible away from the \"edges\" of the experiment. The following cell sorts out the bad data in a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad simulations \n",
    "peak_info_clean = peak_info.copy()\n",
    "variables_clean = variables.copy()\n",
    "variables_rev_clean = variables_rev.copy()\n",
    "peak_info_clean.replace(511,0,inplace=True)\n",
    "peak_info_clean.replace(512,0,inplace=True)\n",
    "peak_info_clean.replace(1023,0,inplace=True)\n",
    "for i in peak_info_clean.columns:\n",
    "    if (i[1] == 'location') & (i[0] != str(0)):\n",
    "        mask = peak_info_clean[i] != 0\n",
    "        peak_info_clean = peak_info_clean[mask]\n",
    "        variables_rev_clean = variables_rev_clean[mask]\n",
    "        variables_clean = variables_clean[mask]\n",
    "print(peak_info_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the back peaks I will use some symmetry descriptors for the wave since we know there is information in the symmetry, and it is uncertain if the describing values for the second half of the peaks include much more information than the first half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_info_clean_sym = peak_info_clean.copy()\n",
    "#zeroth harmonic \n",
    "peak_info_clean_sym[(str(0),'value',str(2))] = (peak_info_clean_sym[(str(0),'value',str(2))] - peak_info_clean[(str(0),'value',str(1))])/peak_info_clean_sym[(str(0),'value',str(1))]\n",
    "# all other harmonics\n",
    "for ind in peak_info_clean.columns:\n",
    "    h = int(ind[0])\n",
    "    pn = int(ind[2])\n",
    "    if (pn > h) & (ind[0] != str(0)):\n",
    "        diff = pn-h\n",
    "        if diff == 1:\n",
    "            ind_ref = (ind[0],ind[1],str(pn-1))\n",
    "        elif diff == 3:\n",
    "            ind_ref = (ind[0],ind[1],str(pn-3))\n",
    "        elif diff == 5:\n",
    "            ind_ref = (ind[0],ind[1],str(pn-5))\n",
    "        elif diff == 7:\n",
    "            ind_ref = (ind[0],ind[1],str(pn-7))\n",
    "        elif diff == 9:\n",
    "            ind_ref = (ind[0],ind[1],str(pn-9))\n",
    "        if ind[1] == 'location':\n",
    "            peak_info_clean_sym[ind] = (peak_info_clean_sym[ind]-511.5)/(511.5-peak_info_clean_sym[ind_ref])\n",
    "        elif ind[1] == 'value':\n",
    "            peak_info_clean_sym[ind] = (peak_info_clean_sym[ind] - peak_info_clean[ind_ref])/peak_info_clean_sym[ind_ref]\n",
    "print(peak_info_clean_sym.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the following cell to get better sense of what the modfied data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic = slice(None)\n",
    "data_type = 'min_value'\n",
    "peak_number = slice(None)\n",
    "peak_info_clean_sym.loc[:,(harmonic,data_type,peak_number)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst there are 68 descriptors I have chosen to use for inital parameter extraction, I will pick 1 or 2 peaks to check visually for correlation with all the target variables.\n",
    "\n",
    "For the ones where there is 1 maximum peak (harmonics 0,1,3,5) I use the maximum peak but for harmonics 2,4 I use the average of the two center/largest peaks. I will also visualise the relationship between the minimums and target variables. \n",
    "\n",
    "In the following figures, you can toggle between different variables, and you will see 6 figures at a time. Each figure represents a harmonic in the following order: [[0,1,2],[3,4,5]]. The red dots represent irreversible reactions, and the blue dots represent reversible reactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Front peak amplitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_front_max = []\n",
    "for var in variables.columns:\n",
    "    plot_front_max = {}\n",
    "    if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "        islog = 'log'\n",
    "    else:\n",
    "        islog = 'linear'\n",
    "    n_maxpeak = [1,1,1.5,2,2.5,3]\n",
    "    for n in range(harmonics_number+1):\n",
    "        x_vals = variables_rev_clean[var]\n",
    "        if (n/2 != round(n/2)) | (n == 0) :\n",
    "            ind = (str(n),'value',str(n_maxpeak[n]))\n",
    "            y_vals = peak_info_clean_sym[ind]\n",
    "        else:\n",
    "            ind1 = (str(n),'value',str(int(n_maxpeak[n]-0.5)))\n",
    "            ind2 = (str(n),'value',str(int(n_maxpeak[n]+0.5)))\n",
    "            y_vals = (peak_info_clean_sym[ind1]+peak_info_clean_sym[ind2])/2\n",
    "        \n",
    "        plot_front_max[n] = Figure(x_axis_type=islog)\n",
    "        plot_front_max[n].scatter(x=x_vals, y=y_vals,fill_color=variables_rev_clean['Is reversible'],line_color=None,alpha=0.05)\n",
    "        plot_front_max[n].toolbar_location=None  \n",
    "    gridplot_front_max = gridplot([[plot_front_max[0],plot_front_max[1],plot_front_max[2]], [plot_front_max[3],plot_front_max[4],plot_front_max[5]]], plot_width=300, plot_height=200)\n",
    "\n",
    "    panels_front_max.append(Panel(child=gridplot_front_max, title=var))\n",
    "\n",
    "full_plot_front_max = Tabs(tabs=panels_front_max)\n",
    "show(full_plot_front_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Front peak location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_front_max_loc = []\n",
    "for var in variables.columns:\n",
    "    plot_front_max_loc = {}\n",
    "    if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "        islog = 'log'\n",
    "    else:\n",
    "        islog = 'linear'\n",
    "    n_maxpeak = [1,1,1.5,2,2.5,3]\n",
    "    for n in range(harmonics_number+1):\n",
    "        x_vals = variables_rev_clean[var]\n",
    "        if n == 0:\n",
    "            x_vals = []\n",
    "            y_vals = []\n",
    "        elif (n/2 != round(n/2)) :\n",
    "            ind = (str(n),'location',str(n_maxpeak[n]))\n",
    "            y_vals = peak_info_clean_sym[ind]\n",
    "        else:\n",
    "            ind1 = (str(n),'location',str(int(n_maxpeak[n]-0.5)))\n",
    "            ind2 = (str(n),'location',str(int(n_maxpeak[n]+0.5)))\n",
    "            y_vals = (peak_info_clean_sym[ind1]+peak_info_clean_sym[ind2])/2\n",
    "        \n",
    "        plot_front_max_loc[n] = Figure(x_axis_type=islog)\n",
    "        if n == 0:\n",
    "            plot_front_max_loc[n].scatter(x=x_vals, y=y_vals,line_color=None,alpha=0.05)\n",
    "        else:\n",
    "            plot_front_max_loc[n].scatter(x=x_vals, y=y_vals,fill_color=variables_rev_clean['Is reversible'],line_color=None,alpha=0.05)\n",
    "        plot_front_max_loc[n].toolbar_location=None  \n",
    "    gridplot_front_max_loc = gridplot([[plot_front_max_loc[0],plot_front_max_loc[1],plot_front_max_loc[2]], [plot_front_max_loc[3],plot_front_max_loc[4],plot_front_max_loc[5]]], plot_width=300, plot_height=200)\n",
    "\n",
    "    panels_front_max_loc.append(Panel(child=gridplot_front_max_loc, title=var))\n",
    "\n",
    "full_plot_front_max_loc = Tabs(tabs=panels_front_max_loc)\n",
    "show(full_plot_front_max_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amplitude symmetry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_max_sym = []\n",
    "for var in variables.columns:\n",
    "    plot_max_sym = {}\n",
    "    if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "        islog = 'log'\n",
    "    else:\n",
    "        islog = 'linear'\n",
    "    n_maxpeak = [2,2,3.5,5,6.5,8]\n",
    "    for n in range(harmonics_number+1):\n",
    "        x_vals = variables_rev_clean[var]\n",
    "        if (n/2 != round(n/2)) | (n == 0) :\n",
    "            ind = (str(n),'value',str(n_maxpeak[n]))\n",
    "            y_vals = peak_info_clean_sym[ind]\n",
    "        else:\n",
    "            ind1 = (str(n),'value',str(int(n_maxpeak[n]-0.5)))\n",
    "            ind2 = (str(n),'value',str(int(n_maxpeak[n]+0.5)))\n",
    "            y_vals = (peak_info_clean_sym[ind1]+peak_info_clean_sym[ind2])/2\n",
    "        \n",
    "        plot_max_sym[n] = Figure(x_axis_type=islog)\n",
    "        plot_max_sym[n].scatter(x=x_vals, y=y_vals,fill_color=variables_rev_clean['Is reversible'],line_color=None,alpha=0.05)\n",
    "        plot_max_sym[n].toolbar_location=None  \n",
    "    gridplot_max_sym = gridplot([[plot_max_sym[0],plot_max_sym[1],plot_max_sym[2]], [plot_max_sym[3],plot_max_sym[4],plot_max_sym[5]]], plot_width=300, plot_height=200)\n",
    "\n",
    "    panels_max_sym.append(Panel(child=gridplot_max_sym, title=var))\n",
    "\n",
    "full_plot_max_sym = Tabs(tabs=panels_max_sym)\n",
    "show(full_plot_max_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location symmetry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_sym_max_loc = []\n",
    "for var in variables.columns:\n",
    "    plot_sym_max_loc = {}\n",
    "    if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "        islog = 'log'\n",
    "    else:\n",
    "        islog = 'linear'\n",
    "    n_maxpeak = [1,1,1.5,2,2.5,3]\n",
    "    for n in range(harmonics_number+1):\n",
    "        x_vals = variables_rev_clean[var]\n",
    "        if n == 0:\n",
    "            x_vals = []\n",
    "            y_vals = []\n",
    "        elif (n/2 != round(n/2)) :\n",
    "            ind = (str(n),'location',str(n_maxpeak[n]))\n",
    "            y_vals = peak_info_clean_sym[ind]\n",
    "        else:\n",
    "            ind1 = (str(n),'location',str(int(n_maxpeak[n]-0.5)))\n",
    "            ind2 = (str(n),'location',str(int(n_maxpeak[n]+0.5)))\n",
    "            y_vals = (peak_info_clean_sym[ind1]+peak_info_clean_sym[ind2])/2\n",
    "        \n",
    "        plot_sym_max_loc[n] = Figure(x_axis_type=islog)\n",
    "        if n == 0:\n",
    "            plot_sym_max_loc[n].scatter(x=x_vals, y=y_vals,line_color=None,alpha=0.05)\n",
    "        else:\n",
    "            plot_sym_max_loc[n].scatter(x=x_vals, y=y_vals,fill_color=variables_rev_clean['Is reversible'],line_color=None,alpha=0.05)\n",
    "        plot_sym_max_loc[n].toolbar_location=None  \n",
    "    gridplot_sym_max_loc = gridplot([[plot_sym_max_loc[0],plot_sym_max_loc[1],plot_sym_max_loc[2]], [plot_sym_max_loc[3],plot_sym_max_loc[4],plot_sym_max_loc[5]]], plot_width=300, plot_height=200)\n",
    "\n",
    "    panels_sym_max_loc.append(Panel(child=gridplot_sym_max_loc, title=var))\n",
    "\n",
    "full_plot_sym_max_loc = Tabs(tabs=panels_sym_max_loc)\n",
    "show(full_plot_sym_max_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimum values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_min = []\n",
    "for var in variables.columns:\n",
    "    plot_min = {}\n",
    "    if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "        islog = 'log'\n",
    "    else:\n",
    "        islog = 'linear'\n",
    "    for n in range(harmonics_number+1):\n",
    "        x_vals = variables_rev_clean[var]\n",
    "        ind = (str(n),'min_value',str(0))\n",
    "        y_vals = peak_info_clean_sym[ind]\n",
    "        \n",
    "        plot_min[n] = Figure(x_axis_type=islog)\n",
    "        plot_min[n].scatter(x=x_vals, y=y_vals,fill_color=variables_rev_clean['Is reversible'],line_color=None,alpha=0.05)\n",
    "        plot_min[n].toolbar_location=None  \n",
    "    gridplot_min = gridplot([[plot_min[0],plot_min[1],plot_min[2]], [plot_min[3],plot_min[4],plot_min[5]]], plot_width=300, plot_height=200)\n",
    "\n",
    "    panels_min.append(Panel(child=gridplot_min, title=var))\n",
    "\n",
    "full_plot_min = Tabs(tabs=panels_min)\n",
    "show(full_plot_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we have 6 datasets that we can investigate individually. We have the full set, that we can split into reversible and irreversible sets. We also have data sets only with peak amplitudes and locations, and sets with symmetry informatin. \n",
    "\n",
    "The first thing to do is to split these different datasets up into train and test sets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "test_ratio = 0.1\n",
    "\n",
    "#Full data set \n",
    "X_train, X_test, y_train, y_test = train_test_split(peak_info_clean, variables_clean, test_size=test_ratio, random_state=1)\n",
    "#Full data set - symmetry descriptors\n",
    "X_sym_train, X_sym_test, y_sym_train, y_sym_test = train_test_split(peak_info_clean_sym, variables_clean, test_size=test_ratio, random_state=1)\n",
    "#Reversible data set \n",
    "X_rev_train, X_rev_test, y_rev_train, y_rev_test = train_test_split(peak_info_clean[reversible_mask], variables_clean[reversible_mask], test_size=test_ratio, random_state=1)\n",
    "#Reversible data set - symmetry descriptors\n",
    "X_rev_sym_train, X_rev_sym_test, y_rev_sym_train, y_rev_sym_test = train_test_split(peak_info_clean_sym[reversible_mask], variables_clean[reversible_mask], test_size=test_ratio, random_state=1)\n",
    "#Irreversible data set \n",
    "X_irrev_train, X_irrev_test, y_irrev_train, y_irrev_test = train_test_split(peak_info_clean[~reversible_mask], variables_clean[~reversible_mask], test_size=test_ratio, random_state=1)\n",
    "#Irreversible data set - symmetry descriptors\n",
    "X_irrev_sym_train, X_irrev_sym_test, y_irrev_sym_train, y_irrev_sym_test = train_test_split(peak_info_clean_sym[~reversible_mask], variables_clean[~reversible_mask], test_size=test_ratio, random_state=1)\n",
    "\n",
    "training_sets = [X_train,X_sym_train,X_rev_train,X_rev_sym_train,X_irrev_train,X_irrev_sym_train]\n",
    "test_sets = [X_test,X_sym_test,X_rev_test,X_rev_sym_test,X_irrev_test,X_irrev_sym_test]\n",
    "training_targets = [y_train,y_sym_train,y_rev_train,y_rev_sym_train,y_irrev_train,y_irrev_sym_train]\n",
    "test_targets = [y_test,y_sym_test,y_rev_test,y_rev_sym_test,y_irrev_test,y_irrev_sym_test]\n",
    "\n",
    "print(f'Full data set: Train: {X_train.shape[0]} Test:{X_test.shape[0]}')\n",
    "print(f'Reversible data set: Train: {X_rev_train.shape[0]} Test:{X_rev_test.shape[0]}')\n",
    "print(f'Irreversible data set: Train: {X_irrev_train.shape[0]} Test:{X_irrev_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I create dataframes that can store the R2 values and biases for each linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [['Not known','Not known','Reversible','Reversible','Irreversible','Irreversible'],\n",
    "          ['Peak values only','Symmetry','Peak values only','Symmetry','Peak values only','Symmetry']]\n",
    "\n",
    "indices = pd.MultiIndex.from_tuples(list(zip(*indices)), names=[\"Reaction type\", \"Data type\"])\n",
    "model_R2 = pd.DataFrame(index = indices,columns = variables.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_vars = []\n",
    "\n",
    "for i in range(len(variables.columns)):\n",
    "    var = variables.columns[i]\n",
    "    model_weights_vars.append(pd.DataFrame(index = indices,columns = peak_info.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains a separate linear regression model for all datasets and all target variables individually. Each data set is first standardised, followed by training and then testing on a scaled test set. For the target variables that span multiple orders of magnitude, the target sets are transformed to a logarithmic scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_sets)):\n",
    "    k=0\n",
    "    for var in variables.columns:\n",
    "        model = LinearRegression()\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        names = training_sets[i].columns\n",
    "        training_data = scaler.fit_transform(training_sets[i])\n",
    "        training_data = pd.DataFrame(training_data, columns=names)\n",
    "        test_data = scaler.transform(test_sets[i])\n",
    "        test_data = pd.DataFrame(test_data, columns=names)\n",
    "        if (var == '$D1') | (var == '$D2') | (var == '$Ks') :\n",
    "            training_target = np.log(training_targets[i][var])\n",
    "            test_target = np.log(test_targets[i][var])\n",
    "        else:\n",
    "            training_target = training_targets[i][var]\n",
    "            test_target = test_targets[i][var]\n",
    "        model.fit(training_data,training_target)\n",
    "        if i/2 == round(i/2):\n",
    "            ind2 = 'Peak values only'\n",
    "        else:\n",
    "            ind2 = 'Symmetry'\n",
    "        if (i == 0) | (i == 1) :\n",
    "            ind1 = 'Not known'\n",
    "        elif (i == 2) | (i == 3) :\n",
    "            ind1 = 'Reversible'\n",
    "        else:\n",
    "            ind1 = 'Irreversible'\n",
    "        ind = (ind1,ind2)\n",
    "        model_R2[var].loc[ind] = model.score(test_data,test_target)\n",
    "        model_weights_vars[k].iloc[i] = model.coef_\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'model_R2' dataframe shows how well a simple linear regression model can extract the physical parameters from the reduced data signal. The 'model_weights_vars' data frames include all weights for the different models, so it can be used to explore the importance of different features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model_weights_vars dataframes include information that can be used to investigate feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(variables.columns[i])\n",
    "model_weights_vars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
